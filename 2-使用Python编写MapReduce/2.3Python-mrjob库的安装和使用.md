<h2>Python-mrjob库的安装和使用</h2>

mrjob是一个Python MapReduce库, 由yelp创建, 封装了Hadoop streaming,允许MapReduce应用程序以更python的方式编写。mrjob允许用纯Python编写多步骤MapReduce作业。MapReduce用 mrjob编写的作业可以在本地进行测试, 在Hadoop群集上运行,或者使用亚马逊弹性云(EMR)中运行。

使用mrjob编写MapReduce有很多的好处:
* mrjob 目前是一个非常活跃的发展框架, 每个星期都有提交多个提交。
* mrjob 有大量文档,比支持Hadoop上的Python的任何其他框架或库都多。
* mrjob 应用程序可以在不安装 hadoop 的情况下执行和测试, 在部署到 hadoop 群集之前启用开发和测试。
* mrjob 允许在单个类中写入 MapReduce 应用程序, 而不是为mapper和reducer编写单独的程。

虽然 mrjob 是一个伟大的解决方案, 它确实有它的缺点。mrjob 是简化的, 因此它不会给出与其他 api 提供的 Hadoop相同的访问级别。mrjob不使用typedbytes,因此其他库可能更快。

<h3>安装</h3>
mrjob 的安装简单;可以使用pip进行安装:

```
$ pip install mrjob
```

或从源码安装:
```
$ python setup.py install
```

<h3>使用mrjob编写WordCount</h3>

* Example 2-3 python/MapReduce/mrjob/word_count.py

```
from mrjob.job import MRJob
class MRWordCount(MRJob):

    def mapper(self, _, line):
        for word in line.split():
        yield(word, 1)

    def reducer(self, word, counts):
        yield(word, sum(counts))

if __name__ == '__main__':
    MRWordCount.run()
```

要在本地运行 mrjob, 唯一需要的是文本正文。要在本地运行作业并计算名为input.txt的文件中单词的频率, 请使用以下命令

```
$ python word_count.py input.txt
```
输出取决于输入文件的内容, 但应该和以下类似:

```
"be" 2
"jack" 2
"nimble" 1
"quick" 1
```

<h3>处理过程</h3>
MapReduce作业被定义为类MRWordCount。在mrjob库中,从mrjob继承的类包含定义MapReduce作业步骤的方法。mrjob应用程序中的步骤是mapper,commbiner,reducer。继承MRJob的类只需要定义以下步骤之一:

* mapper()

mapper()方法为MapReduce作业定义映射程序。它以键和值作为参数,并生成元组(output_key、output_value)。在上述WordCount示例中,mapper忽略了输入键并拆分输入值以生成单词和计数。

* combiner()

combiner()方法定义MapReduce作业的组合。combiner()是一个过程,在mapper后运行，在reducer前运行。它接收mapper发出的所有数据作为输入,并将该输出发送到reducer。该combiner的输入是一个键,由mapper生成,并且是一个值,它产生的所有值都由一个对应于该键的mapper产生。combiner生成 (output_key, output_value) 元组作为输出。

* reducer()

reducer()方法为MapReduce作业定义reducer。它需要一个键和一个值的迭代器作为参数,并生成元组 (output_key, output_value)。在例2-4 中,reducer对每个键的值求和, 表示输入中的单词频率。

用mrjob库编写的MapReduce作业的调用:

```
if __name__ == '__main__':
    MRWordCount.run()
```

<h3>执行mrjob</h3>
使用mrjob执行MapReduce应用程序类似于执行其他Python程序。在命令行必须包含mrjob应用程序的名称和输入文件:

```
$ python mr_job.py input.txt
```

默认情况下，mrjob将数据到标准输出。可以向mrjob传递多个文件：

```
$ python mr_job.py input1.txt input2.txt input3.txt
```

mrjob也可以处理通过标准输入的数据：

```
$ python mr_job.py < input.txt
```

默认情况下,mrjob先在本开发调试地运行,然后在提交到Hadoop群集上。改变任务的执行方式，指定 **-r/--runner** 的选项，以下列表展示了不同选项的作用:

|                     |                                      |
| --------------------|--------------------------------------|
|    -r inline        |  (默认),python 单进程执行             |
|    -r local         |  多python进程，模拟一些Haddoop的特征   |
|    -r hadoop        |  在Hadoop集群上执行                   |
|    -r emr           |  在Amzon弹性云上执行                  |
|                     |                                      |

使用"runner"选项,可以在Hadoop群集上运行mrjob程序,并从HDFS中指定输入。

```
$ python mr_job.py -r hadoop hdfs://input/input.txt
```

mrjob应用程序也允许在Amzon弹性云上执行：

```
$ python mr_job.py -r emr s3://input-bucket/input.txt
```

<h3>计算最高工资实例</h3>
Example2-5 使用mrjob计算员工的的最高工资和总支出，使用的测试数据集是2014年巴尔的摩薪资情况：

* Example 2-5. python/MapReduce/mrjob/top_salary.py

```
from mrjob.job import MRJob
from mrjob.step import MRStep
import csv
cols = 'Name,JobTitle,AgencyID,Agency,HireDate,AnnualSalary,GrossPay'.split(',')
class salarymax(MRJob):
	def mapper(self, _, line):
		# Convert each line into a dictionary
		row = dict(zip(cols, [ a.strip() for a in csv.reader([line]).next()]))
		
		# Yield the salary
		yield 'salary', (float(row['AnnualSalary'][1:]), line)
		
		# Yield the gross pay
		try:
			yield 'gross', (float(row['GrossPay'][1:]), line)
	    except ValueError:
			self.increment_counter('warn', 'missing gross', 1)

    def reducer(self, key, values):
        topten = []
        # For 'salary' and 'gross' compute the top 10
        for p in values:
            topten.append(p)
            topten.sort()
            topten = topten[-10:]
        for p in topten:
            yield key, p

    combiner = reducer

if __name__ == '__main__':
    salarymax.run()
```

使用以下命令在Hadoop集群上执行mrjob程序:

```
$ python top_salary.py -r hadoop hdfs:///user/hduser/input/salaries.csv
```


