<h2>Hadoop数据流</h2>

hadoop流是一个实用工具,附带了Hadoop分布式功能, 允许创建任何可执的mapper/reducer的MapReduce作业。Hadoop流实用程序使Python、shell脚本或任何其他语言都可以用作mapper、reducer或二者。

<h3>工作机制</h3>
mapper和reducer都是从标准输入一行一行读取、输出到标准输出。Hadoop流程序创建MapReduce作业,将作业提交到群集,并监视其进度, 直到完成。初始化映射程序时, 每个映射任务将指定的可执行文件作为单独的进程启动。mapper读取输入文件, 并通过stdin向可执行文件显示每一行。在可执行文件处理每一行输入之后, mapper从标准输出中收集结果, 并将每一行转换为键值对。该键由第一个 tab 字符之前行的部分组成, 该值由第一个制表符后面的行部分组成。如果行不包含制表符, 则整行被视为键, 值为 null。

在初始化reducer时,每个reducer任务都将指定的可执行文件作为单独的进程启动。reducer将输入键值对转换行通过标准输入传递给可执行程序。reducer从标准输出中收集可执行文件结果, 并将每一行转换为键值对。与mapper类似,可执行文件通过tab制表符分隔键和值来指定键值对。

<h3>python程序示例</h3>

为了演示hadoop流实用程序如何在hadoop群集上以MapReduce应用程序的方式运行Python, WordCount应用程序可以由两个Python程序实现:mapper.py
和reducer.py

mapper.py是在WordCount的映射阶段实现逻辑的Python程序。它从标准输入读取数据, 将行拆分为单词, 并将每个单词的中间计数输出到标准输出。example2-1实现mapper.py的逻辑:

* Example 2-1.python/MapReduce/HadoopStreaming/mapper.py

```
#!/usr/bin/env python
import sys

# Read each line from stdin
for line in sys.stdin:
    # Get the words in each line
    words = line.split()

# Generate the count for each word
for word in words:
    # Write the key-value pair to stdout to be processed by
    # the reducer.
    # The key is anything before the first tab character and the
    #value is anything after the first tab character.
    print '{0}\t{1}'.format(word, 1)

```

reducer.py是WordCount的聚合阶段实现逻辑的Python程序，通过标准输入读取Mapper生成的数据，统计单词的词频，并将数据写入到标准输出。

* Example 2-2.python/MapReduce/HadoopStreaming/reducer.py

```
import sys
curr_word = None
curr_count = 0

# Process each key-value pair from the mapper
for line in sys.stdin:
    # Get the key and value from the current line
    word, count = line.split('\t')

    # Convert the count to an int
    count = int(count)

    # If the current word is the same as the previous word,
    # increment its count, otherwise print the words count
    # to stdout
    if word == curr_word:
        curr_count += count
    else:
        # Write word and its number of occurrences as a key-value
        # pair to stdout
        if curr_word:
            print '{0}\t{1}'.format(curr_word, curr_count)
        curr_word = word

        curr_count = count

    # Output the count for the last word
    if curr_word == word:
        print '{0}\t{1}'.format(curr_word, curr_count)
```

在尝试执行代码之前,请确mapper.py和reducer.py文件具有执行权限。以下命令将对python脚本赋予执行权限:
```
$ chmod a+x mapper.py reducer.py
```

还要确保每个文件的第一行包含Python的正确路径。第一行的路径说明能让mapper.py和reducer.py能独立运行。对于#!/usr/bin/env python 在绝大多数系统中都可以使用，但是如果其不起作用，使用系统上python路径来代替
/usr/bin/env python。

要在本地测试Python程序,将它们作为MapReduce作业运行, 可以使用echo和sort命令运行它们。强烈建议在对所有程序进行本地测试在上Hadoop群集之前。

```
$ echo 'jack be nimble jack be quick' | ./mapper.py
| sort -t 1 | ./reducer.py
be 2
jack 2
nimble 1
quick 1
```

一旦mapper和reducer程序成功测试完毕，就可以通过Hadoop Streaming进行MapReduce计算，具体的执行命令如下

```
$ $HADOOP_HOME/bin/hadoop jar
$HADOOP_HOME/mapred/contrib/streaming/hadoop-streaming*.jar \
-files mapper.py,reducer.py \
-mapper mapper.py \
-reducer reducer.py \
-input /user/hduser/input.txt -output /user/hduser/output
```

* Hadoop Streaming的相关选项

|  option     |     描述                               |
|-------------|--------------------------------------  |
| -file       | 要复制到 MapReduce 群集的文件的分隔列表  |
| -mapper     | 作为mapper 程序执行                    |
| -reducer    | 作为reducer程序执行                     |
| -input      | 在Map阶段DFS输入路径                    |
| -output     | 在reduce阶段DFS输出路径                 |